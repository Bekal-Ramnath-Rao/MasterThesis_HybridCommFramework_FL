# Dynamic Client Support - Complete Update Summary

## ðŸŽ¯ What Was Updated

All FL servers across all protocols (MQTT, AMQP, gRPC, QUIC, DDS, Unified) and all use cases (Emotion, Mental State, Temperature) have been updated to support **dynamic client counts**.

## âœ… Changes Made

### 1. **Server Code Updates** (18 files)
All server files have been updated with:

#### Configuration Changes:
```python
# OLD (hardcoded 2 clients):
NUM_CLIENTS = int(os.getenv("NUM_CLIENTS", "2"))

# NEW (dynamic with min/max):
MIN_CLIENTS = int(os.getenv("MIN_CLIENTS", "2"))  # Minimum clients to start training
MAX_CLIENTS = int(os.getenv("MAX_CLIENTS", "100"))  # Maximum clients allowed
```

#### Server Class Updates:
```python
# OLD:
def __init__(self, num_clients, num_rounds):
    self.num_clients = num_clients

# NEW:
def __init__(self, min_clients, num_rounds, max_clients=100):
    self.min_clients = min_clients
    self.max_clients = max_clients
    self.num_clients = min_clients  # Start with minimum, will update as clients join
```

#### New Methods Added:
- `update_client_count(new_count)` - Dynamically updates expected client count
- `handle_late_joining_client(client_id)` - Handles clients joining after training starts
- `get_active_clients()` - Returns list of currently active clients
- `adaptive_wait_for_clients(client_dict, timeout)` - Smart waiting for client responses

#### Registration Logic:
```python
# OLD (exact match required):
if len(self.registered_clients) == self.num_clients:
    # Start training

# NEW (minimum threshold):
if len(self.registered_clients) >= self.min_clients:
    # Start training
    
# PLUS dynamic update:
if len(self.registered_clients) > self.num_clients:
    self.update_client_count(len(self.registered_clients))
```

#### Aggregation Logic:
```python
# OLD (wait for fixed count):
if len(self.client_updates) == self.num_clients:
    self.aggregate_models()

# NEW (wait for all registered):
if len(self.client_updates) >= len(self.registered_clients):
    self.aggregate_models()
```

#### Evaluation Logic:
```python
# OLD (wait for fixed count):
if len(self.client_metrics) == self.num_clients:
    self.evaluate_round()

# NEW (wait for all registered):
if len(self.client_metrics) >= len(self.registered_clients):
    self.evaluate_round()
```

### 2. **Docker Compose Updates** (17 files)
All docker-compose files now include:
```yaml
environment:
  - NUM_ROUNDS=1000
  - MIN_CLIENTS=${MIN_CLIENTS:-2}      # NEW
  - MAX_CLIENTS=${MAX_CLIENTS:-100}    # NEW
  - CUDA_VISIBLE_DEVICES=
```

### 3. **Distributed Client GUI** (Already updated earlier)
- Uses correct port mappings (31883 for MQTT, 35672 for AMQP)
- Uses existing client images with `-1` suffix
- Supports dynamic client IDs

## ðŸ“‚ Updated Files

### Server Files (18 total):
```
Server/Emotion_Recognition/
  â”œâ”€â”€ FL_Server_MQTT.py âœ…
  â”œâ”€â”€ FL_Server_AMQP.py âœ…
  â”œâ”€â”€ FL_Server_gRPC.py âœ…
  â”œâ”€â”€ FL_Server_QUIC.py âœ…
  â”œâ”€â”€ FL_Server_DDS.py âœ…
  â””â”€â”€ FL_Server_Unified.py âœ…

Server/MentalState_Recognition/
  â”œâ”€â”€ FL_Server_MQTT.py âœ…
  â”œâ”€â”€ FL_Server_AMQP.py âœ…
  â”œâ”€â”€ FL_Server_gRPC.py âœ…
  â”œâ”€â”€ FL_Server_QUIC.py âœ…
  â”œâ”€â”€ FL_Server_DDS.py âœ…
  â””â”€â”€ FL_Server_Unified.py âœ…

Server/Temperature_Regulation/
  â”œâ”€â”€ FL_Server_MQTT.py âœ…
  â”œâ”€â”€ FL_Server_AMQP.py âœ…
  â”œâ”€â”€ FL_Server_gRPC.py âœ…
  â”œâ”€â”€ FL_Server_QUIC.py âœ…
  â”œâ”€â”€ FL_Server_DDS.py âœ…
  â””â”€â”€ FL_Server_Unified.py âœ…
```

### Docker Compose Files (17 total):
```
Docker/
  â”œâ”€â”€ docker-compose-emotion.gpu-isolated.yml âœ…
  â”œâ”€â”€ docker-compose-emotion.gpu.yml âœ…
  â”œâ”€â”€ docker-compose-emotion.yml âœ…
  â”œâ”€â”€ docker-compose-mentalstate.gpu-isolated.yml âœ…
  â”œâ”€â”€ docker-compose-mentalstate.gpu.yml âœ…
  â”œâ”€â”€ docker-compose-mentalstate.yml âœ…
  â”œâ”€â”€ docker-compose-temperature.gpu-isolated.yml âœ…
  â”œâ”€â”€ docker-compose-temperature.gpu.yml âœ…
  â”œâ”€â”€ docker-compose-temperature.yml âœ…
  â”œâ”€â”€ docker-compose-unified-emotion.yml âœ…
  â”œâ”€â”€ docker-compose-unified-mentalstate.yml âœ…
  â””â”€â”€ docker-compose-unified-temperature.yml âœ…
```

## ðŸ”§ Backups Created

All original files backed up as:
- Server files: `*.bak_dynamic_clients`
- Docker compose files: `*.bak_clients`

## ðŸš€ How to Use

### 1. **Start Experiment with Specific Client Count**

From experiment GUI, set "Min Clients" in the GUI (line 472-476 in experiment_gui.py):
```python
self.min_clients = QSpinBox()
self.min_clients.setRange(1, 100)
self.min_clients.setValue(2)  # Change this value
```

Or via environment variables:
```bash
export MIN_CLIENTS=3
export MAX_CLIENTS=10
cd Network_Simulation
python3 experiment_gui.py
```

### 2. **Add Distributed Clients**

From distributed client GUI on any PC:
```bash
cd Network_Simulation
./launch_distributed_client.sh

# In GUI:
# Server IP: 129.69.102.245
# Client ID: 3, 4, 5, etc.
# Use Case: emotion (match experiment)
# Protocol: mqtt (match experiment)
```

### 3. **Dynamic Behavior**

**Scenario 1: All clients join before training starts**
- Server waits for MIN_CLIENTS (e.g., 2)
- Clients 1, 2 register â†’ Training starts
- Client 3 joins later â†’ Dynamically added to training

**Scenario 2: Clients join during training**
- Training ongoing with clients 1, 2
- Client 3 joins â†’ Receives current global model
- Server updates client_count: 2 â†’ 3
- All 3 clients included in next round's aggregation

**Scenario 3: Variable client count per round**
- Round 1: 2 clients participate
- Round 2: 3 clients participate (client 3 joined)
- Round 3: 4 clients participate (client 4 joined)
- Each round waits for all currently registered clients

## ðŸ“Š Behavior Examples

### Example 1: Standard 2-Client Setup
```bash
# Start experiment with 2 clients (default)
MIN_CLIENTS=2 MAX_CLIENTS=10
# Training starts when 2 clients register
# Can add up to 10 total clients during training
```

### Example 2: 5-Client Distributed Setup
```bash
# Experiment PC:
MIN_CLIENTS=3 MAX_CLIENTS=10
# Start experiment (includes 2 local clients)

# Remote PC 1:
# Start distributed client (ID=3)

# Remote PC 2:
# Start distributed client (ID=4)

# Remote PC 3:
# Start distributed client (ID=5)

# Training starts when 3 clients registered
# All 5 clients participate in aggregation
```

### Example 3: Late-Joining Clients
```bash
# Training already running with clients 1, 2
# New client 3 joins:
# 1. Registers with server
# 2. Receives current global model
# 3. Starts training from current round
# 4. Included in all subsequent aggregations
```

## ðŸ” Verification

Check server logs to see dynamic behavior:
```
Client 1 registered (1/2 expected, min: 2)
Client 2 registered (2/2 expected, min: 2)

All clients registered. Distributing initial global model...
Training started at: 2026-02-04 15:30:00

# Later, client 3 joins:
[LATE JOIN] Client 3 joined after training started
[DYNAMIC] Updated client count: 2 -> 3
Client 3 registered (3/3 expected, min: 2)
```

## ðŸŽ¯ Key Benefits

1. **Flexible Client Count**: No longer limited to 2 clients
2. **Dynamic Scaling**: Clients can join during training
3. **All Clients Included**: Every registered client participates in aggregation and evaluation
4. **Minimum Threshold**: Training starts when minimum clients reached
5. **Maximum Limit**: Prevents resource exhaustion with too many clients
6. **Late-Join Support**: Clients joining mid-training receive current model
7. **Fair Aggregation**: All registered clients weighted in model aggregation

## ðŸ› Troubleshooting

### Issue: Training not starting
**Check**: Do you have at least MIN_CLIENTS registered?
```bash
# In experiment GUI, check logs for:
Client 1 registered (1/2 expected, min: 2)
# Need 2 clients if MIN_CLIENTS=2
```

### Issue: New client not participating
**Check**: Did server detect the registration?
```bash
# Look for in server logs:
[LATE JOIN] Client X joined after training started
[DYNAMIC] Updated client count: Y -> Z
```

### Issue: Aggregation hanging
**Check**: Are all registered clients responding?
```bash
# Server logs show:
Received update from client 1 (1/3)
Received update from client 2 (2/3)
# Waiting for client 3...
```

## ðŸ“ˆ Next Steps

1. âœ… **DONE**: All servers updated for dynamic clients
2. âœ… **DONE**: Docker compose files updated
3. âœ… **DONE**: Distributed client GUI ready
4. ðŸ”„ **TODO**: Rebuild Docker images
5. ðŸ”„ **TODO**: Test with 3+ distributed clients

### Rebuild Docker Images

**For single protocol (e.g., MQTT emotion)**:
```bash
cd Docker
docker-compose -f docker-compose-emotion.gpu-isolated.yml build
```

**For unified/RL scenario**:
```bash
cd Docker
docker-compose -f docker-compose-unified-emotion.yml build
```

**Or use the GUI**:
- Go to "Docker Build" tab
- Click appropriate build button
- Wait for completion

## ðŸŽ‰ Summary

**18 server files** + **17 docker-compose files** = **35 files updated**

All FL servers now support:
- âœ… Dynamic client registration (2 to 100 clients)
- âœ… Late-joining clients receive current model
- âœ… All registered clients included in aggregation
- âœ… All registered clients included in evaluation
- âœ… Configurable min/max client limits
- âœ… Graceful handling of variable client counts per round

Ready for distributed federated learning experiments! ðŸš€

# Distributed Federated Learning System - README

## ğŸŒ Overview

This system enables **true distributed federated learning** across multiple physical machines on the same network. Run the main experiment on one PC and connect additional clients from other PCs to simulate realistic heterogeneous FL scenarios.

## ğŸ“ Key Files Created

### GUI Applications
1. **[Network_Simulation/distributed_client_gui.py](Network_Simulation/distributed_client_gui.py)**
   - GUI for running FL clients on remote PCs
   - Features: connection testing, network simulation, real-time monitoring
   - Use: `python3 distributed_client_gui.py`

2. **[Network_Simulation/launch_distributed_client.sh](Network_Simulation/launch_distributed_client.sh)**
   - Launch script for distributed client GUI
   - Use: `./launch_distributed_client.sh`

### Update Scripts
3. **[update_dynamic_client_support.py](update_dynamic_client_support.py)**
   - Updates FL servers to support dynamic client joining
   - Adds late-joining client handling and adaptive convergence
   - Use: `python3 update_dynamic_client_support.py`

### Documentation
4. **[DISTRIBUTED_CLIENT_SETUP.md](DISTRIBUTED_CLIENT_SETUP.md)**
   - Complete setup guide with architecture, troubleshooting, best practices
   - 800+ lines of comprehensive documentation

5. **[DISTRIBUTED_CLIENT_QUICK_START.md](DISTRIBUTED_CLIENT_QUICK_START.md)**
   - Quick reference guide (TL;DR version)
   - Essential commands and configurations

## ğŸš€ Quick Start

### Step 1: Main Experiment PC
```bash
cd Network_Simulation
python3 experiment_gui.py
```
- Set "Number of Clients" to total (e.g., 4 for 2 local + 2 remote)
- Note server IP: `hostname -I`

### Step 2: Remote PC(s)
```bash
cd Network_Simulation
./launch_distributed_client.sh
```
- Enter server IP
- Configure client ID (unique)
- Select same use case as main experiment
- Start client

## âœ¨ Features

### Distributed Architecture
- **Multi-PC Support**: Run clients on different machines
- **Network Heterogeneity**: Each client can simulate different network conditions
- **Real-World Scenarios**: Test FL with actual network latency and limited bandwidth

### Dynamic Client Management
- **Late Joining**: Clients can join mid-experiment
- **Adaptive Server**: Automatically adjusts to variable client count (min 2)
- **Convergence Adaptation**: Resets convergence checks when new clients join
- **Graceful Handling**: Server waits for all registered clients each round

### Network Simulation (Per Client)
Each client can independently simulate:
- Excellent (5ms latency, 100Mbps)
- Good (20ms, 50Mbps)
- Moderate (50ms, 20Mbps)
- Poor (100ms, 5Mbps)
- Very Poor (200ms, 1Mbps)
- Satellite (600ms, 10Mbps)
- Congestion (Light/Moderate/Heavy)

### Protocol Support
All 5 communication protocols supported:
- MQTT (port 1883)
- AMQP/RabbitMQ (port 5672)
- gRPC (port 50051)
- QUIC (port 4433)
- DDS (auto-discovery)

**RL-Unified Mode**: Clients automatically select best protocol per round

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Main Experiment PC             â”‚
â”‚  IP: 192.168.1.100                  â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FL Server (Unified)        â”‚   â”‚
â”‚  â”‚  â€¢ MQTT Broker              â”‚   â”‚
â”‚  â”‚  â€¢ RabbitMQ Broker          â”‚   â”‚
â”‚  â”‚  â€¢ gRPC Server              â”‚   â”‚
â”‚  â”‚  â€¢ QUIC Server              â”‚   â”‚
â”‚  â”‚  â€¢ DDS Domain               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚Client 1  â”‚  â”‚Client 2  â”‚        â”‚
â”‚  â”‚(Docker)  â”‚  â”‚(Docker)  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        Networkâ”‚(LAN/WiFi)
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                 â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚Remote PC 1 â”‚   â”‚Remote PC 2 â”‚   â”‚Remote PCâ”‚
â”‚192.168.1.2 â”‚   â”‚192.168.1.3 â”‚   â”‚...      â”‚
â”‚            â”‚   â”‚            â”‚   â”‚         â”‚
â”‚  Client 3  â”‚   â”‚  Client 4  â”‚   â”‚Client N â”‚
â”‚  (Docker)  â”‚   â”‚  (Docker)  â”‚   â”‚(Docker) â”‚
â”‚            â”‚   â”‚            â”‚   â”‚         â”‚
â”‚ Network:   â”‚   â”‚ Network:   â”‚   â”‚Network: â”‚
â”‚  Poor      â”‚   â”‚  Satellite â”‚   â”‚Excellentâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requirements

### Server PC (Main Experiment)
- Ubuntu 20.04+
- Docker & Docker Compose
- Python 3.8+
- 32GB RAM, 8+ CPU cores
- NVIDIA GPU (8GB+ VRAM)
- Gigabit Ethernet

### Client PCs (Remote)
- Ubuntu 20.04+ or similar Linux
- Docker installed
- Python 3.8+ with PyQt5
- 8GB RAM, 4+ CPU cores
- 100Mbps+ network (WiFi acceptable)
- GPU optional (4GB+ VRAM if enabled)

### Network
- All PCs on same network (LAN or WiFi)
- Firewall ports open: 1883, 5672, 50051, 4433
- Minimum 100Mbps connectivity recommended

## ğŸ”§ Installation

### Main PC
```bash
# Already have experiment_gui.py
cd Network_Simulation
python3 experiment_gui.py
```

### Remote PCs
```bash
# Copy distributed client files
git clone <repository-url>
cd MasterThesis_HybridCommFramework_FL/Network_Simulation

# Install dependencies
pip3 install PyQt5

# Launch client GUI
./launch_distributed_client.sh
```

## ğŸ¯ Use Cases

### Scenario 1: Heterogeneous Network Study
- **Main PC**: 2 clients with excellent network
- **Remote PC 1**: 1 client with poor network (mobile simulation)
- **Remote PC 2**: 1 client with satellite network (high latency)
- **Goal**: Study impact of network heterogeneity on FL convergence

### Scenario 2: Scalability Testing
- **Main PC**: Server only (or 1 client)
- **Remote PCs**: 5-10 clients distributed across machines
- **Goal**: Test server scalability with many distributed clients

### Scenario 3: Dynamic Participation
- **Phase 1**: Start with 2 clients
- **Phase 2**: After 10 rounds, add 2 remote clients
- **Phase 3**: Observe convergence adaptation
- **Goal**: Study impact of clients joining mid-training

### Scenario 4: Protocol Comparison
- **Client 1-2** (Main PC): Use RL-Unified
- **Client 3** (Remote): Fixed to gRPC
- **Client 4** (Remote): Fixed to MQTT
- **Goal**: Compare RL-selected vs fixed protocol performance

## ğŸ” Security Notes

âš ï¸ **Warning**: This setup is for research/development on trusted networks.

For production:
- Enable SSL/TLS for all protocols
- Use authentication (MQTT, AMQP)
- Configure restrictive firewall rules
- Use VPN for remote connections
- Implement client authentication

## ğŸ“Š Monitoring

### Main Experiment GUI
- **Experiment Output**: Overall progress
- **FL Training Monitor**: Per-round metrics
- **Server Logs**: Server-side events
- **Client Logs**: Select any client to view logs
- **Packet Logs**: Network traffic analysis

### Distributed Client GUI
- **Connection Status**: Real-time connectivity indicator
- **Client Logs**: Local client container logs
- **Status Info**: Training progress, round number

## ğŸ› Troubleshooting

### Connection Failed
```bash
# Check server IP
hostname -I

# Test connectivity
ping <server-ip>
nc -zv <server-ip> 1883

# Check firewall
sudo ufw status
sudo ufw allow 1883/tcp
```

### Container Won't Start
```bash
# Check if image exists
docker images | grep fl-client

# Remove conflicting container
docker rm fl-client-X-distributed

# Check Docker logs
docker logs fl-client-X-distributed
```

### Server Not Waiting
```bash
# Check server environment
docker exec fl-server-unified env | grep NUM_CLIENTS

# Update server
python3 update_dynamic_client_support.py
docker-compose -f Docker/docker-compose-unified-<usecase>.yml build
```

## ğŸ“š Documentation Index

| Document | Purpose | Length |
|----------|---------|--------|
| [DISTRIBUTED_CLIENT_SETUP.md](DISTRIBUTED_CLIENT_SETUP.md) | Complete guide | Full |
| [DISTRIBUTED_CLIENT_QUICK_START.md](DISTRIBUTED_CLIENT_QUICK_START.md) | Quick reference | Quick |
| This README | Overview | Summary |

## ğŸ”„ Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SETUP PHASE                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Start experiment_gui.py on main PC              â”‚
â”‚ 2. Configure experiment (protocols, use case, etc.)â”‚
â”‚ 3. Set total client count (local + remote)         â”‚
â”‚ 4. Note server IP address                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              REMOTE PC SETUP                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Launch distributed_client_gui.py                â”‚
â”‚ 2. Enter server IP and test connection             â”‚
â”‚ 3. Configure client (ID, use case, network)        â”‚
â”‚ 4. Repeat for each remote PC                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             START EXPERIMENT                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Click "Start Experiment" on main PC             â”‚
â”‚ 2. Server waits for all clients to register        â”‚
â”‚ 3. Click "Start Client" on each remote GUI         â”‚
â”‚ 4. Training begins when all clients connected      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          TRAINING & MONITORING                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Main GUI shows aggregated metrics                â”‚
â”‚ â€¢ Remote GUIs show individual client logs          â”‚
â”‚ â€¢ Network conditions applied per client            â”‚
â”‚ â€¢ RL selects protocols dynamically                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            COMPLETION                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Convergence achieved or max rounds reached       â”‚
â”‚ â€¢ Results saved to shared_data/                    â”‚
â”‚ â€¢ Clients automatically stopped                    â”‚
â”‚ â€¢ Review metrics in experiment GUI                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Research Applications

This distributed setup enables:
- **Realistic FL Experiments**: True network conditions, not just simulation
- **Heterogeneity Studies**: Mix of powerful/weak devices, good/poor networks
- **Scalability Research**: Test with many geographically distributed clients
- **Protocol Comparison**: Compare performance across real network conditions
- **Dynamic Participation**: Study client churn and late-joining behavior
- **Resource Utilization**: Leverage multiple machines for parallel experiments

## ğŸ¤ Contributing

When adding features:
1. Update [distributed_client_gui.py](Network_Simulation/distributed_client_gui.py) for client-side
2. Update [FL_Server_Unified.py](Server/*/FL_Server_Unified.py) for server-side
3. Run [update_dynamic_client_support.py](update_dynamic_client_support.py) if needed
4. Update documentation
5. Test with at least 2 remote PCs

## ğŸ“ License

Same as main project

## ğŸ‘¨â€ğŸ’» Author

Part of Master Thesis: Hybrid Communication Framework for Federated Learning

---

**Quick Commands**:
```bash
# Main PC
python3 Network_Simulation/experiment_gui.py

# Remote PC
./Network_Simulation/launch_distributed_client.sh

# Update server (if needed)
python3 update_dynamic_client_support.py
```

For detailed instructions, see [DISTRIBUTED_CLIENT_SETUP.md](DISTRIBUTED_CLIENT_SETUP.md)

# ğŸ‰ GUI Enhanced - New Monitoring Features

## What's New (v1.1)

### ğŸš€ Major Enhancements

#### 1. **Multi-Tab Output System**

The single output console has been replaced with a comprehensive **4-tab monitoring system**:

**ğŸ“Š Tab 1: Experiment Output**
- Main experiment execution logs
- Docker compose commands
- Protocol/scenario progress
- Results summary

**ğŸ“ˆ Tab 2: FL Training Monitor (vs Baseline)**
- **NEW!** Integrated `fl_training_dashboard.py`
- Real-time training metrics
- **Baseline comparison** - see how current experiment compares to baseline
- Round-by-round accuracy, loss, and RTT
- Performance indicators (âœ… outperforming / âš ï¸ underperforming)
- Auto-refreshes every 5 seconds

**ğŸ–¥ï¸ Tab 3: Server Logs**
- Live streaming of FL server container logs
- Model aggregation progress
- Round completion status
- Server-side errors/warnings
- Color-coded (green theme)

**ğŸ’» Tab 4: Client Logs**
- Live streaming of FL client container logs
- Training progress on clients
- Parameter updates
- Client-side communication status
- Color-coded (yellow theme)

---

#### 2. **Dynamic Network Control**

**NEW Button: "ğŸŒ Apply Network Changes"**

Apply network conditions **during** running experiments using `fl_network_monitor.py`:

**How it works:**
1. Adjust sliders in "Network Control" tab:
   - Latency (0-1000ms)
   - Bandwidth (1-1000 Mbps)
   - Jitter (0-100ms)
   - Packet Loss (0-10%)

2. Click "ğŸŒ Apply Network Changes" button

3. Conditions applied immediately to all FL clients via host-level `tc` (traffic control)

4. See real-time impact in Training Monitor and logs

**Use Cases:**
- Simulate mobile device handoffs (good â†’ poor â†’ good network)
- Test protocol resilience to sudden network degradation
- Study adaptive behavior under varying conditions
- Dynamic congestion scenarios

---

#### 3. **Baseline Comparison Integration**

The GUI now automatically loads baseline experiment results for comparison:

**Features:**
- Loads baseline data from `experiment_results_baseline/`
- Compares current experiment with baseline in real-time
- Shows delta (Î”) between current and baseline metrics
- Visual indicators:
  - âœ… Green: Outperforming baseline
  - âš ï¸ Yellow: Close to baseline
  - âŒ Red: Underperforming baseline

**What You'll See:**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FL Training Monitor - emotion (vs Baseline)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Protocol: MQTT | Scenario: moderate | Round: 5/10

Current Experiment:
  Accuracy: 0.82 | Loss: 0.35 | RTT: 12.3s

Baseline:
  Accuracy: 0.78 | Loss: 0.42 | RTT: 15.1s

Comparison:
  Î” Accuracy: +0.04 (+5.1%) âœ…
  Î” Loss: -0.07 (-16.7%) âœ…  
  Î” RTT: -2.8s (-18.5%) âœ…

Status: âœ… OUTPERFORMING BASELINE!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

#### 4. **Automatic Container Detection**

The GUI now automatically:
- Detects running FL containers
- Starts log monitoring for server and first client
- Updates logs in real-time
- Handles container restarts gracefully

---

#### 5. **Enhanced Thread Safety**

**New Background Threads:**
- `ExperimentRunner`: Runs main experiment
- `DashboardMonitor`: Monitors FL training with baseline comparison
- `LogMonitor` (Ã—2): Monitors server and client logs
- `NetworkController`: Applies network conditions

**Cleanup:**
- Proper thread termination on experiment stop
- Cleanup on GUI close
- Confirmation dialog if experiment running

---

## Technical Implementation

### New Classes

```python
class DashboardMonitor(QThread):
    """Monitors fl_training_dashboard.py output"""
    
class LogMonitor(QThread):
    """Monitors Docker container logs"""
    
class NetworkController(QThread):
    """Applies network conditions via fl_network_monitor.py"""
```

### Integration Points

1. **fl_training_dashboard.py**
   - Started automatically when experiment begins
   - Monitors baseline comparison
   - Updates every 5 seconds
   - Stops when experiment completes

2. **fl_network_monitor.py**
   - Triggered by "Apply Network Changes" button
   - Applies conditions to all clients
   - Uses host-level veth interfaces
   - Immediate effect, no container restart needed

3. **Docker logs**
   - Uses `docker logs -f --tail 50 <container>`
   - Streams to separate tabs
   - Auto-scrolls to bottom
   - Color-coded for clarity

---

## How to Use

### Basic Workflow (Same as Before)

1. Configure experiment in tabs 1-3
2. Click "â–¶ï¸ Start Experiment"
3. **NEW:** Switch between output tabs to monitor different aspects
4. Review results when complete

### Advanced Workflow (Dynamic Network Control)

1. Start experiment normally
2. **While running:**
   - Go to "Network Control" tab
   - Adjust sliders (e.g., increase latency to 200ms)
   - Click "ğŸŒ Apply Network Changes"
   - Watch impact in Training Monitor tab
3. Repeat to simulate various network conditions
4. Compare final results with baseline

### Monitoring Workflow

1. Start experiment
2. **Tab switching:**
   - **Experiment Output**: Overall progress
   - **FL Training Monitor**: Round-by-round comparison with baseline
   - **Server Logs**: Server-side activities
   - **Client Logs**: Client-side training
3. Identify issues quickly with color-coded logs

---

## Screenshots

### Main Window with Tabs
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš€ FL Experiment Dashboard                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[Configuration Tabs...]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–¶ï¸ Start  â¹ï¸ Stop  ğŸŒ Apply Network  ğŸ—‘ï¸ Clear     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ğŸ“Š Exp â”‚ğŸ“ˆ FL Monitor  â”‚ğŸ–¥ï¸ Server â”‚ğŸ’» Client   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚  [Output content with color-coded text...]          â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Benefits

### For Researchers

âœ… **Compare with Baseline**: Instantly see if new protocols/conditions improve over baseline
âœ… **Real-time Insights**: Spot issues during training, not after
âœ… **Dynamic Testing**: Test protocol resilience without restarting experiments
âœ… **Comprehensive Logging**: All logs in one place, organized by source

### For Development

âœ… **Debugging**: Separate server/client logs make debugging easier
âœ… **Monitoring**: See exactly what's happening at each layer
âœ… **Validation**: Confirm network conditions are applied correctly
âœ… **Performance**: Track resource usage and bottlenecks

### For Analysis

âœ… **Baseline Comparison**: Built-in comparison reduces manual analysis
âœ… **Export-ready**: All logs captured for later analysis
âœ… **Visual Indicators**: Quick status checks with color coding
âœ… **Historical Context**: Compare against known-good baseline runs

---

## Updated Files

### Code Changes
- `Network_Simulation/experiment_gui.py`: +200 lines
  - Added 3 new QThread classes
  - Added 4-tab output system
  - Added network control integration
  - Added baseline monitoring integration
  - Enhanced thread safety and cleanup

### Documentation Updates
- `GUI_USER_GUIDE.md`: Updated monitoring section
- `GUI_SUMMARY.md`: Added new features
- `GUI_ENHANCED_FEATURES.md`: This file (new)

---

## Backward Compatibility

âœ… **Fully Compatible**: All existing features work as before
âœ… **No Breaking Changes**: Old workflows still function
âœ… **Graceful Degradation**: Works even if baseline data missing
âœ… **Optional Features**: Network control and monitoring are opt-in

---

## Future Enhancements

Potential additions:
- Multi-client log aggregation
- Graph visualization of training curves
- Save/load monitoring snapshots
- Export logs to file
- Filtering and search in logs
- Performance metrics dashboard

---

## Troubleshooting

### Dashboard Not Showing Data

**Cause**: Baseline data missing or fl_training_dashboard.py not executable

**Solution**:
```bash
# Ensure baseline data exists
ls experiment_results_baseline/emotion/

# Check script
python3 Network_Simulation/fl_training_dashboard.py --use-case emotion
```

### Logs Not Appearing

**Cause**: Containers not started yet or wrong container names

**Solution**:
- Wait 5 seconds after experiment start
- Check containers: `docker ps`
- Logs will appear once containers are running

### Network Changes Not Applied

**Cause**: fl_network_monitor.py not working or no containers

**Solution**:
```bash
# Test manually
python3 Network_Simulation/fl_network_monitor.py --all --latency 100ms

# Check veth interfaces
python3 Network_Simulation/fl_network_monitor.py --show-status
```

---

## Version History

**v1.1** (2026-01-29)
- âœ… Added 4-tab output system
- âœ… Integrated FL training dashboard with baseline comparison
- âœ… Added server and client log streaming
- âœ… Added dynamic network control button
- âœ… Enhanced thread management
- âœ… Improved cleanup on exit

**v1.0** (2026-01-29)
- Initial release with basic features

---

## Credits

**Integration with Existing Tools:**
- `fl_training_dashboard.py` - Real-time training monitoring
- `fl_network_monitor.py` - Dynamic network control
- Baseline comparison framework from FL_BASELINE_IMPLEMENTATION.md

---

ğŸ‰ **The GUI is now a comprehensive experiment monitoring and control center!**

For questions, see [GUI_USER_GUIDE.md](GUI_USER_GUIDE.md)

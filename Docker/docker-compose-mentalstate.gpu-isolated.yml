# Docker Compose for Emotion Recognition with GPU Support (Device-Isolated)
# This version isolates GPU devices to prevent memory contention between clients
# Client 1 uses GPU 0, Client 2 uses GPU 1, Server uses both but with memory limits
# Requires: 2+ NVIDIA GPUs with NVIDIA Container Toolkit
# Note: Uses Docker Compose V2 syntax (no version: field)

services:
  mqtt-broker:
    image: eclipse-mosquitto:latest
    ports:
      - "31883:1883"
      - "39001:9001"
    volumes:
      - ../mqtt-config/mosquitto.conf:/mosquitto/config/mosquitto.conf
    networks:
      - mentalstate_network
    container_name: mqtt-broker-mentalstate

  # ============================================================================
  # MQTT Protocol Services
  # ============================================================================
  
  fl-server-mqtt-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=MQTT
      - USE_CASE=mentalstate
      - MQTT_BROKER=mqtt-broker:1883
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=0,1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.4
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - mqtt-broker
    networks:
      - mentalstate_network
    container_name: fl-server-mqtt-mentalstate
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-mqtt-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_MQTT.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1']

  fl-client-mqtt-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=MQTT
      - USE_CASE=mentalstate
      - MQTT_BROKER=mqtt-broker:1883
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - mqtt-broker
      - fl-server-mqtt-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-mqtt-mentalstate-1
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-mqtt-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_MQTT.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-mqtt-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=MQTT
      - USE_CASE=mentalstate
      - MQTT_BROKER=mqtt-broker:1883
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - mqtt-broker
      - fl-server-mqtt-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-mqtt-mentalstate-2
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-mqtt-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_MQTT.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

  # ============================================================================
  # AMQP Protocol Services
  # ============================================================================
  
  amqp-broker:
    image: rabbitmq:3.12-management
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    ports:
      - "35672:5672"
      - "35671:15672"
    networks:
      - mentalstate_network
    container_name: amqp-broker-mentalstate

  fl-server-amqp-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=AMQP
      - USE_CASE=mentalstate
      - AMQP_BROKER=amqp://guest:guest@amqp-broker:5672/
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=0,1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.4
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - amqp-broker
    networks:
      - mentalstate_network
    container_name: fl-server-amqp-mentalstate
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-amqp-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_AMQP.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1']

  fl-client-amqp-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=AMQP
      - USE_CASE=mentalstate
      - AMQP_BROKER=amqp://guest:guest@amqp-broker:5672/
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - amqp-broker
      - fl-server-amqp-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-amqp-mentalstate-1
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-amqp-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_AMQP.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-amqp-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=AMQP
      - USE_CASE=mentalstate
      - AMQP_BROKER=amqp://guest:guest@amqp-broker:5672/
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - amqp-broker
      - fl-server-amqp-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-amqp-mentalstate-2
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-amqp-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_AMQP.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

  # ============================================================================
  # gRPC Protocol Services
  # ============================================================================
  
  fl-server-grpc-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=gRPC
      - USE_CASE=mentalstate
      - GRPC_PORT=50051
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=0,1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.4
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    ports:
      - "50051:50051"
    networks:
      - mentalstate_network
    container_name: fl-server-grpc-mentalstate
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-grpc-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_gRPC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1']

  fl-client-grpc-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=gRPC
      - USE_CASE=mentalstate
      - GRPC_SERVER=fl-server-grpc-mentalstate:50051
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-grpc-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-grpc-mentalstate-1
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-grpc-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_gRPC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-grpc-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=gRPC
      - USE_CASE=mentalstate
      - GRPC_SERVER=fl-server-grpc-mentalstate:50051
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-grpc-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-grpc-mentalstate-2
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-grpc-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_gRPC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

  # ============================================================================
  # QUIC Protocol Services
  # ============================================================================
  
  fl-server-quic-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=QUIC
      - USE_CASE=mentalstate
      - QUIC_PORT=4433
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=0,1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.4
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    ports:
      - "4433:4433/udp"
    networks:
      - mentalstate_network
    container_name: fl-server-quic-mentalstate
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-quic-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_QUIC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1']

  fl-client-quic-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=QUIC
      - USE_CASE=mentalstate
      - QUIC_SERVER=fl-server-quic-mentalstate:4433
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-quic-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-quic-mentalstate-1
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-quic-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_QUIC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-quic-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=QUIC
      - USE_CASE=mentalstate
      - QUIC_SERVER=fl-server-quic-mentalstate:4433
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-quic-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-quic-mentalstate-2
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-quic-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_QUIC.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

  # ============================================================================
  # HTTP/3 Protocol Services
  # ============================================================================
  
  fl-server-http3-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=HTTP3
      - USE_CASE=mentalstate
      - HTTP3_HOST=0.0.0.0
      - HTTP3_PORT=4434
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=  # Server runs on CPU only (no GPU needed for aggregation)
      - USE_QUANTIZATION=${USE_QUANTIZATION:-false}
      - QUANTIZATION_STRATEGY=${QUANTIZATION_STRATEGY:-parameter_quantization}
      - QUANTIZATION_BITS=${QUANTIZATION_BITS:-8}
      - QUANTIZATION_SYMMETRIC=${QUANTIZATION_SYMMETRIC:-true}
      - QUANTIZATION_PER_CHANNEL=${QUANTIZATION_PER_CHANNEL:-false}
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    cap_add:
      - NET_ADMIN
    ports:
      - "4434:4434"
    volumes:
      - ../experiment_results:/app/experiment_results
      - ../certs:/app/certs:ro
      - ../Server/MentalState_Recognition/results:/app/Server/MentalState_Recognition/results
    networks:
      - mentalstate_network
    container_name: fl-server-http3-mentalstate
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-http3-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_HTTP3.py"]
    # Server runs on CPU to avoid competing for GPU memory with clients

  fl-client-http3-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=HTTP3
      - USE_CASE=mentalstate
      - HTTP3_HOST=fl-server-http3-mentalstate
      - HTTP3_PORT=4434
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - USE_QUANTIZATION=${USE_QUANTIZATION:-false}
      - QUANTIZATION_STRATEGY=${QUANTIZATION_STRATEGY:-parameter_quantization}
      - QUANTIZATION_BITS=${QUANTIZATION_BITS:-8}
      - QUANTIZATION_SYMMETRIC=${QUANTIZATION_SYMMETRIC:-true}
      - QUANTIZATION_PER_CHANNEL=${QUANTIZATION_PER_CHANNEL:-false}
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    cap_add:
      - NET_ADMIN
    depends_on:
      - fl-server-http3-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-http3-mentalstate-1
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-http3-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_HTTP3.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-http3-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=HTTP3
      - USE_CASE=mentalstate
      - HTTP3_HOST=fl-server-http3-mentalstate
      - HTTP3_PORT=4434
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - USE_QUANTIZATION=${USE_QUANTIZATION:-false}
      - QUANTIZATION_STRATEGY=${QUANTIZATION_STRATEGY:-parameter_quantization}
      - QUANTIZATION_BITS=${QUANTIZATION_BITS:-8}
      - QUANTIZATION_SYMMETRIC=${QUANTIZATION_SYMMETRIC:-true}
      - QUANTIZATION_PER_CHANNEL=${QUANTIZATION_PER_CHANNEL:-false}
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    cap_add:
      - NET_ADMIN
    depends_on:
      - fl-server-http3-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-http3-mentalstate-2
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-http3-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_HTTP3.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

  # ============================================================================
  # DDS Protocol Services
  # ============================================================================
  
  fl-server-dds-mentalstate:
    build:
      context: ..
      dockerfile: Server/Dockerfile
    environment:
      - PROTOCOL=DDS
      - USE_CASE=mentalstate
      - NUM_ROUNDS=1000
      - MIN_CLIENTS=${MIN_CLIENTS:-2}
      - MAX_CLIENTS=${MAX_CLIENTS:-100}
      - CUDA_VISIBLE_DEVICES=0,1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.4
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    networks:
      - mentalstate_network
    container_name: fl-server-dds-mentalstate
    cap_add:
      - NET_ADMIN
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-server-dds-mentalstate.pcap & python -u Server/MentalState_Recognition/FL_Server_DDS.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0', '1']

  fl-client-dds-mentalstate-1:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=1
      - NUM_CLIENTS=2
      - PROTOCOL=DDS
      - USE_CASE=mentalstate
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE_ID=0
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-dds-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-dds-mentalstate-1
    cap_add:
      - NET_ADMIN
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-dds-mentalstate-1.pcap & python -u Client/MentalState_Recognition/FL_Client_DDS.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['0']

  fl-client-dds-mentalstate-2:
    build:
      context: ..
      dockerfile: Client/Dockerfile
    environment:
      - CLIENT_ID=2
      - NUM_CLIENTS=2
      - PROTOCOL=DDS
      - USE_CASE=mentalstate
      - CUDA_VISIBLE_DEVICES=1
      - GPU_DEVICE_ID=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - TF_GPU_MEMORY_FRACTION=0.9
      - FL_EXPERIMENT_SUBDIR=${FL_EXPERIMENT_SUBDIR:-network_captures}
    depends_on:
      - fl-server-dds-mentalstate
    networks:
      - mentalstate_network
    container_name: fl-client-dds-mentalstate-2
    cap_add:
      - NET_ADMIN
    command: ["sh", "-c", "mkdir -p /app/experiment_results/$FL_EXPERIMENT_SUBDIR && tcpdump -i any -w /app/experiment_results/$FL_EXPERIMENT_SUBDIR/fl-client-dds-mentalstate-2.pcap & python -u Client/MentalState_Recognition/FL_Client_DDS.py"]
    volumes:
      - ../experiment_results:/app/experiment_results
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              device_ids: ['1']

networks:
  mentalstate_network:
    driver: bridge
